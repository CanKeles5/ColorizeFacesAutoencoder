{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColorizeFacesAutoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CanKeles5/ColorizeFacesAutoencoder/blob/master/ColorizeFacesAutoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NObvWvCS7Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68YZPopgTXBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as DS\n",
        "import torch.optim as optim\n",
        "import torch.utils.data.sampler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import *\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader as DL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idfTw6hhTYMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o66do9uwTYIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aFC_PNTTYFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = DS.ImageFolder(root='../input/celeba-dataset/img_align_celeba', transform=tfms)\n",
        "train_loader = DL(train_set, batch_size=4, shuffle=True)\n",
        "\n",
        "print(len(train_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmpxP_tvTYDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset_indices = range(500)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, sampler=SubsetRandomSampler(subset_indices))\n",
        "\n",
        "print(len(subset_indices))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8jFJ35TYAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.dconv_1 = double_conv(1, 16)\n",
        "        self.dconv_2 = double_conv(16, 32)\n",
        "        self.dconv_3 = double_conv(32, 64)\n",
        "        self.dconv_4 = double_conv(64, 128)\n",
        "        self.dconv_5 = double_conv(128, 256)\n",
        "        \n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.upconv_4 = double_conv(256, 128)\n",
        "        self.upconv_3 = double_conv(128, 64)\n",
        "        self.upconv_2 = double_conv(64, 32)\n",
        "        self.upconv_1 = double_conv(20, 3)\n",
        "        \n",
        "        self.TConv4 = nn.ConvTranspose2d(256, 128, 2, stride=2, padding=0)\n",
        "        self.TConv3 = nn.ConvTranspose2d(128, 64, 2, stride=2, padding=0)\n",
        "        self.TConv2 = nn.ConvTranspose2d(64, 32, 2, stride=2, padding=0)\n",
        "        self.TConv1 = nn.ConvTranspose2d(32, 4, 2, stride=2, padding=0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "        \n",
        "        conv2 = self.dconv_2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_3(x)\n",
        "        x = self.maxpool(conv3)\n",
        "        \n",
        "        conv4 = self.dconv_4(x)\n",
        "        x = self.maxpool(conv4)\n",
        "        \n",
        "        x = self.dconv_5(x)\n",
        "                \n",
        "        x = self.TConv4(x)\n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "        x = self.upconv_4(x)\n",
        "                \n",
        "        x = self.TConv3(x)\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.upconv_3(x)\n",
        "                \n",
        "        x = self.TConv2(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        x = self.upconv_2(x)\n",
        "                \n",
        "        x = self.TConv1(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        x = self.upconv_1(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raG3_NUuTX-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = AutoEncoder()\n",
        "\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Au9mBgTTX8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeYK8tn0TX6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (X, _) in enumerate(train_loader):\n",
        "        y = X\n",
        "        X = (0.2989*X[:,0,:,:] + 0.5870*X[:,1,:,:] + 0.1140*X[:,2,:,:]) #RGB to grayscale\n",
        "        \n",
        "        X = X.unsqueeze(1)\n",
        "        \n",
        "        X = Variable(X.to(device))\n",
        "        y = Variable(y.to(device))\n",
        "        \n",
        "        X *= 255\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = criterion(output, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    print(\"loss for epoch \" + str(epoch) + \": \" + str(running_loss/500))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9GvX9ljTX3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "for i in range(5):\n",
        "    im, _ = train_set[i]\n",
        "    orig = im\n",
        "    \n",
        "    im = im.unsqueeze(0)\n",
        "    im = (0.2989*im[:,0,:,:] + 0.5870*im[:,1,:,:] + 0.1140*im[:,2,:,:])\n",
        "    im = im.unsqueeze(0)\n",
        "    \n",
        "    im = im.to(device)\n",
        "    im *= 255\n",
        "    \n",
        "    output = model(im)\n",
        "    output = output.squeeze(0)\n",
        "    \n",
        "    output = output.clamp(0.0, 1.0)\n",
        "    \n",
        "    PIL_img = transforms.ToPILImage()(output.detach().cpu())\n",
        "    PIL_img = PIL_img.save(str(i) + \".jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}